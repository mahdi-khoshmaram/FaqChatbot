{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "># **FAQ ChatBOT**\n",
        "># **This Notebook is created by: [mahdi khoshmaram](https://github.com/mahdi-khoshmaram)** ðŸ¤—\n",
        ">\n",
        "> In this notebook, the goal is to design a chatbot to map the User prompt to FAQ questions. For developing this chatbot I used:\n",
        ">*   A Bert model **[sentence transformers](https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2)** for **Sentence Embedding** which supports persian language.\n",
        ">*  **ChromaDB**, an open-source vector database designed for the efficient storage and retrieval of vector embeddings, for handling my embeddings.\n",
        ">*  **Resdis** an in-memory database for **Chatbot's RPS**(Request Per Second) handeling.\n",
        ">* **[Hazm](https://www.roshan-ai.ir/hazm/docs/index.htmlhttps://www.roshan-ai.ir/hazm/docs/index.html)**, a python library based on NLTK to preprocess Persian text.\n",
        "\n",
        "\n",
        "## â­ Like this notebook? Support by starring the repo!  \n",
        "\n",
        "If you found this notebook helpful, consider giving a â­ to the repository! It helps and motivates me to create more useful content.  \n",
        "\n",
        "[![GitHub Repo](https://img.shields.io/badge/GitHub-Repo-blue?logo=github)](your-repo-link-here)  \n",
        "\n",
        "Your support is greatly appreciated! ðŸš€"
      ],
      "metadata": {
        "id": "yjGxclKcXV94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%pip install chromadb\n",
        "%pip install hazm\n",
        "%pip install redis"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LVBF-EdA7G5S"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from chromadb.utils import embedding_functions\n",
        "from hazm import *\n",
        "import chromadb\n",
        "import shutil\n",
        "import redis\n",
        "import json\n",
        "import time\n",
        "import re"
      ],
      "metadata": {
        "id": "WbRFdXBdAZlr"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!apt-get update\n",
        "!apt-get install redis-server\n",
        "!redis-server --daemonize yes"
      ],
      "metadata": {
        "id": "YhMW-pnW3PKc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Preprocess:\n",
        "    def __init__(self, remove_stopwords=True, lemmatize=True):\n",
        "        self.normalizer = Normalizer()\n",
        "        self.lemmatizer = Lemmatizer()\n",
        "        self.stopwords = set(stopwords_list())\n",
        "        self.remove_stopwords = remove_stopwords\n",
        "        self.lemmatize = lemmatize\n",
        "\n",
        "    def clean(self, text):\n",
        "        def process(t):\n",
        "            t = self.normalizer.normalize(t)\n",
        "            tokens = word_tokenize(t)\n",
        "\n",
        "            if self.remove_stopwords:\n",
        "                tokens = [word for word in tokens if word not in self.stopwords]\n",
        "            if self.lemmatize:\n",
        "                tokens = [self.lemmatizer.lemmatize(word).split(\"#\")[0] for word in tokens]\n",
        "\n",
        "            tokens = [re.sub(r\"[^\\w\\s]\", \"\", word) for word in tokens]\n",
        "            tokens = [word for word in tokens if word.strip()]\n",
        "            return \" \".join(tokens)\n",
        "\n",
        "        if isinstance(text, list):\n",
        "            return [process(t) for t in text]\n",
        "        return process(text)"
      ],
      "metadata": {
        "id": "aWeVW9OCLn72"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VectorMind:\n",
        "    def __init__(self, modelName, chromaCollectionName, space, do_preprocess, db_path='./chromadb'):\n",
        "        self.client = chromadb.PersistentClient(path=db_path)\n",
        "        self.chromaCollectionName = chromaCollectionName\n",
        "        self.preprocess = Preprocess()\n",
        "        self.modelName = modelName\n",
        "        self.space = space\n",
        "        self.do_preprocess = do_preprocess\n",
        "\n",
        "    def embedFaqAndSave(self, FaqQuestions):\n",
        "        self.FaqQuestions = FaqQuestions\n",
        "        self.model = embedding_functions.SentenceTransformerEmbeddingFunction(model_name = self.modelName)\n",
        "\n",
        "        if self.chromaCollectionName in self.client.list_collections():\n",
        "            self.client.delete_collection(name = self.chromaCollectionName)\n",
        "\n",
        "        self.collection = self.client.create_collection(\n",
        "            name = self.chromaCollectionName,\n",
        "            embedding_function = self.model,\n",
        "            metadata={\n",
        "                \"hnsw:space\": self.space,\n",
        "                \"hnsw:search_ef\": 100}\n",
        "            )\n",
        "\n",
        "\n",
        "        if self.do_preprocess:\n",
        "            self.FaqQuestionsForDB = self.preprocess.clean(self.FaqQuestions)\n",
        "            self.faqIDs = [str(index) for index in range(len(self.FaqQuestionsForDB))]\n",
        "        else:\n",
        "            self.FaqQuestionsForDB = self.FaqQuestions\n",
        "            self.faqIDs = [str(index) for index in range(len(self.FaqQuestionsForDB))]\n",
        "\n",
        "        self.collection.add(\n",
        "            documents = list(self.FaqQuestionsForDB),\n",
        "            ids = list(self.faqIDs)\n",
        "            )\n",
        "\n",
        "\n",
        "    def query(self, prompt, top_k=2, threshold=50):\n",
        "\n",
        "        if self.do_preprocess:\n",
        "            self.Prompt = self.preprocess.clean(prompt)\n",
        "        else:\n",
        "            self.Prompt = prompt\n",
        "        if isinstance(self.Prompt, str):\n",
        "            self.Prompt = [self.Prompt]\n",
        "\n",
        "        self.top_k = top_k\n",
        "        self.numberOfPrompts = len(self.Prompt)\n",
        "\n",
        "        self.query_result = self.collection.query(\n",
        "            query_texts=self.Prompt,\n",
        "            n_results = self.top_k)\n",
        "\n",
        "        result_ids = self.query_result[\"ids\"]\n",
        "        result_documents = self.query_result[\"documents\"]\n",
        "        result_distances = self.query_result[\"distances\"]\n",
        "        result_similarity = [[round((1-distance)*100,2) for distance in row] for row in result_distances]\n",
        "\n",
        "        # One of longest dictionary comprehensions I've ever wrote! =)))))))\n",
        "        self.result = {f\"Prompt{i}\":{\"UserPrompt\":self.Prompt[i], \"results\":{f\"result{k}\":{\"FAQ\":result_documents[i][k], \"Index\": result_ids[i][k], \"similarity\":result_similarity[i][k]} for k in range(self.top_k) if result_similarity[i][k]>=threshold}} for i in range(self.numberOfPrompts)}\n",
        "        self.result = json.dumps(dict(self.result), ensure_ascii=False, indent=4)\n",
        "\n",
        "        return self.result"
      ],
      "metadata": {
        "id": "XHAZ5x5rhWjI"
      },
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Chatbot(VectorMind):\n",
        "    def __init__(self, faqQuestions, modelName, chromaCollectionName, space, do_preprocess, db_path='./chromadb',host='localhost', port=6379, db=0, rate_limit=1):\n",
        "        super().__init__(modelName, chromaCollectionName, space, do_preprocess, db_path)\n",
        "        super().embedFaqAndSave(FaqQuestions=faqQuestions)\n",
        "        self.redis_client = redis.Redis(host=host, port=port, db=db)\n",
        "        self.rate_limit = rate_limit\n",
        "\n",
        "    def is_allowed(self, user_id=1):\n",
        "        key = f\"rate_limit:{user_id}\"\n",
        "        last_request_time = self.redis_client.get(key)\n",
        "        current_time = time.time()\n",
        "\n",
        "        if last_request_time and (current_time - float(last_request_time) < self.rate_limit):\n",
        "            return False\n",
        "        self.redis_client.set(key, current_time)\n",
        "        return True\n",
        "\n",
        "    def call(self, myPrompt, top_k=1, threshold=50, user_id=1):\n",
        "        if not self.is_allowed(user_id):\n",
        "            return \"Too many requests! Try again in a second.\"\n",
        "\n",
        "        response = super().query(myPrompt, top_k=top_k, threshold=threshold)\n",
        "        return response\n"
      ],
      "metadata": {
        "id": "IPdAUR4a6gFE"
      },
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {
        "id": "9-N-tLfVVzAy"
      },
      "outputs": [],
      "source": [
        "faq_questions = [\n",
        "    \"Ø¯Ø± ØµÙˆØ±Øª ÙØ±Ø§Ù…ÙˆØ´ÛŒ Ø±Ù…Ø² Ù…ÙˆØ¨Ø§ÛŒÙ„ Ø¨Ø§Ù†Ú© Ùˆ ÛŒØ§ Ø§ÛŒÙ†ØªØ±Ù†Øª Ø¨Ø§Ù†Ú© Ú†Ù‡ Ø§Ù‚Ø¯Ø§Ù…ÛŒ Ø¨Ø§ÛŒØ³ØªÛŒ Ø§Ù†Ø¬Ø§Ù… Ø¯Ø§Ø¯ØŸ\",\n",
        "    \"Ù…Ø¯Øª Ø²Ù…Ø§Ù† Ø¯Ø±ÛŒØ§ÙØª Ú©Ø§Ø±Øª ÙØ±Ø§Ø±ÙØ§Ù‡ Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ\",\n",
        "    \"Ø³Ù‚Ù Ø§Ù†ØªÙ‚Ø§Ù„ ÙˆØ¬Ù‡ Ø¯Ø± Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù…ÙˆØ¨Ø§ÛŒÙ„ Ø¨Ø§Ù†Ú© Ùˆ Ø§ÛŒÙ†ØªØ±Ù†Øª Ø¨Ø§Ù†Ú© Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ\",\n",
        "    \"Ø¨Ø±Ø§ÛŒ Ø§Ù†ØªÙ‚Ø§Ù„ ÙˆØ¬Ù‡ Ù¾Ø§ÛŒØ§ Ùˆ Ø³Ø§ØªÙ†Ø§ Ø¨Ø§ÛŒØ¯ Ø§Ø² Ú†Ù‡ Ø±Ù…Ø²ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯ØŸ\",\n",
        "    \"Ø¨Ø±Ø§ÛŒ Ø«Ø¨Øª Ú†Ú© ØµÛŒØ§Ø¯ÛŒ Ø§Ø² Ú†Ù‡ Ù†ÙˆØ¹ Ø±Ù…Ø²ÛŒ Ø¨Ø§ÛŒØ¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯ØŸ\",\n",
        "    \"Ø¢ÛŒØ§ Ø¯Ø±ÛŒØ§ÙØª ØªØ³Ù‡ÛŒÙ„Ø§Øª Ø¨Ø¯ÙˆÙ† Ø¶Ø§Ù…Ù† Ùˆ Ø¨Ø¯ÙˆÙ† Ø³Ù¾Ø±Ø¯Ù‡ Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø±Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù…Ù…Ú©Ù† Ø§Ø³ØªØŸ\",\n",
        "    \"Ø¹Ù„Øª Ø¹Ø¯Ù… ÙˆØ±ÙˆØ¯ Ø¨Ù‡ Ù…ÙˆØ¨Ø§ÛŒÙ„ Ø¨Ø§Ù†Ú© Ø¯Ø±Ú¯ÙˆØ´ÛŒ Ø´ÛŒØ§Ø¦ÙˆÙ…ÛŒ Ú†ÛŒØ³ØªØŸ\",\n",
        "    \"ØªØºÛŒÛŒØ± Ø±Ù…Ø² Ø§ÙˆÙ„ Ùˆ Ø¯ÙˆÙ… Ù…ÙˆØ¨Ø§ÛŒÙ„ Ø¨Ø§Ù†Ú© Ø§Ø² Ú†Ù‡ Ø±ÙˆØ´ Ù‡Ø§ÛŒÛŒ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒ Ø´ÙˆØ¯ØŸ\",\n",
        "    \"Ø±Ù…Ø² Ù¾ÙˆÛŒØ§ Ø§Ø² Ú†Ù‡ Ø·Ø±ÛŒÙ‚ÛŒ ÙØ¹Ø§Ù„ Ù…ÛŒ Ø´ÙˆØ¯ØŸ\",\n",
        "    \"Ø¯Ø± Ø§ÛŒÙ†ØªØ±Ù†Øª Ø¨Ø§Ù†Ú© Ø­Ù‚ÙˆÙ‚ÛŒ Ú†Ú¯ÙˆÙ†Ù‡ Ù…ÛŒ Ø´ÙˆØ¯ ØªØ§ÛŒÛŒØ¯ Ù†Ù‡Ø§ÛŒÛŒ Ø±Ø§ Ø§Ù†Ø¬Ø§Ù… Ø¯Ø§Ø¯ØŸ\",\n",
        "    \"Ø¢ÛŒØ§ Ø§Ù…Ú©Ø§Ù† Ø¯Ø±ÛŒØ§ÙØª ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø§Ø² Ø·Ø±ÛŒÙ‚ Ù…ÙˆØ¨Ø§ÛŒÙ„ Ø¨Ø§Ù†Ú© ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŸ\",\n",
        "    \"Ø¨Ù‡ Ú†Ù‡ Ø·Ø±ÛŒÙ‚ÛŒ Ù…ÛŒ ØªÙˆØ§Ù† Ø´Ù…Ø§Ø±Ù‡ Ø´Ø¨Ø§ Ùˆ Ø­Ø³Ø§Ø¨ Ø±Ø§ Ø§Ø² Ø¨Ø§Ù†Ú© Ø±ÙØ§Ù‡ Ø¯Ø±ÛŒØ§ÙØª Ù†Ù…ÙˆØ¯ØŸ\",\n",
        "    \"Ù†Ø­ÙˆÙ‡ ØªØ§ÛŒÛŒØ¯ Ø¹Ù…Ù„ÛŒØ§Øª Ø§Ù†Ø¬Ø§Ù… ØªØ±Ø§Ú©Ù†Ø´ Ø¯Ø± Ù…ÙˆØ¨Ø§ÛŒÙ„ Ø¨Ø§Ù†Ú© Ùˆ Ø§ÛŒÙ†ØªØ±Ù†Øª Ø¨Ø§Ù†Ú© Ú†Ú¯ÙˆÙ†Ù‡ Ø§Ø³ØªØŸ\",\n",
        "    \"Ù‚Ø§Ù†ÙˆÙ† Ø¬Ø¯ÛŒØ¯ ØµØ¯ÙˆØ± Ú†Ú©\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot = Chatbot(\n",
        "    faqQuestions=faq_questions,\n",
        "    modelName=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
        "    chromaCollectionName=\"faqCollection\",\n",
        "    space=\"cosine\",\n",
        "    do_preprocess=False)"
      ],
      "metadata": {
        "id": "G87ePxxf_yHr"
      },
      "execution_count": 297,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myPrompts = [\"Ú†Ø·ÙˆØ±ÛŒ Ø±Ù…Ø² Ù¾ÙˆÛŒØ§ Ø¨Ú¯ÛŒØ±Ù…ØŸ\", \"Ú†Ø·ÙˆØ±ÛŒ Ø´Ù…Ø§Ø±Ù‡ Ø´Ø¨Ø§ Ø¨Ú¯ÛŒØ±Ù…ØŸ\", \"Ø³Ù„Ø§Ù…ØŒ Ù…Ù† Ù…Ù‡Ø¯ÛŒ Ø§Ù…!\"]\n",
        "print(chatbot.call(myPrompts, top_k=1, threshold=50))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvwuspnQHZi7",
        "outputId": "2823220b-1ce1-4f0b-bec3-ee6287d93e1e"
      },
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"Prompt0\": {\n",
            "        \"UserPrompt\": \"Ú†Ø·ÙˆØ±ÛŒ Ø±Ù…Ø² Ù¾ÙˆÛŒØ§ Ø¨Ú¯ÛŒØ±Ù…ØŸ\",\n",
            "        \"results\": {\n",
            "            \"result0\": {\n",
            "                \"FAQ\": \"Ø±Ù…Ø² Ù¾ÙˆÛŒØ§ Ø§Ø² Ú†Ù‡ Ø·Ø±ÛŒÙ‚ÛŒ ÙØ¹Ø§Ù„ Ù…ÛŒ Ø´ÙˆØ¯ØŸ\",\n",
            "                \"Index\": \"8\",\n",
            "                \"similarity\": 72.33\n",
            "            }\n",
            "        }\n",
            "    },\n",
            "    \"Prompt1\": {\n",
            "        \"UserPrompt\": \"Ú†Ø·ÙˆØ±ÛŒ Ø´Ù…Ø§Ø±Ù‡ Ø´Ø¨Ø§ Ø¨Ú¯ÛŒØ±Ù…ØŸ\",\n",
            "        \"results\": {\n",
            "            \"result0\": {\n",
            "                \"FAQ\": \"Ø¨Ù‡ Ú†Ù‡ Ø·Ø±ÛŒÙ‚ÛŒ Ù…ÛŒ ØªÙˆØ§Ù† Ø´Ù…Ø§Ø±Ù‡ Ø´Ø¨Ø§ Ùˆ Ø­Ø³Ø§Ø¨ Ø±Ø§ Ø§Ø² Ø¨Ø§Ù†Ú© Ø±ÙØ§Ù‡ Ø¯Ø±ÛŒØ§ÙØª Ù†Ù…ÙˆØ¯ØŸ\",\n",
            "                \"Index\": \"11\",\n",
            "                \"similarity\": 50.5\n",
            "            }\n",
            "        }\n",
            "    },\n",
            "    \"Prompt2\": {\n",
            "        \"UserPrompt\": \"Ø³Ù„Ø§Ù…ØŒ Ù…Ù† Ù…Ù‡Ø¯ÛŒ Ø§Ù…!\",\n",
            "        \"results\": {}\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test Cases**"
      ],
      "metadata": {
        "id": "lw0_Ad1rGc6w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test Case 1:**\n",
        "\n",
        "*   `top_k = 1`:   returns top 1 similar FAQ question\n",
        "\n",
        "\n",
        "*   `threshold = 10`: returns similar FAQ questions with similarity rate higher than 10%"
      ],
      "metadata": {
        "id": "7w8SJqNnGzNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "myPrompts = [\"Ú†Ø·ÙˆØ±ÛŒ Ø±Ù…Ø² Ù¾ÙˆÛŒØ§ Ø¨Ú¯ÛŒØ±Ù…ØŸ\", \"Ú†Ø·ÙˆØ±ÛŒ Ø´Ù…Ø§Ø±Ù‡ Ø´Ø¨Ø§ Ø¨Ú¯ÛŒØ±Ù…ØŸ\", \"Ø³Ù„Ø§Ù…ØŒ Ù…Ù† Ù…Ù‡Ø¯ÛŒ Ø§Ù…!\"]\n",
        "for prompt in myPrompts:\n",
        "    print(chatbot.call(prompt, top_k=2, threshold=50))\n",
        "    time.sleep(0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdws7YYIE5kg",
        "outputId": "bd47a429-8cfb-4e7c-ca6e-18be4abb3cb4"
      },
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"Prompt0\": {\n",
            "        \"UserPrompt\": \"Ú†Ø·ÙˆØ±ÛŒ Ø±Ù…Ø² Ù¾ÙˆÛŒØ§ Ø¨Ú¯ÛŒØ±Ù…ØŸ\",\n",
            "        \"results\": {\n",
            "            \"result0\": {\n",
            "                \"FAQ\": \"Ø±Ù…Ø² Ù¾ÙˆÛŒØ§ Ø§Ø² Ú†Ù‡ Ø·Ø±ÛŒÙ‚ÛŒ ÙØ¹Ø§Ù„ Ù…ÛŒ Ø´ÙˆØ¯ØŸ\",\n",
            "                \"Index\": \"8\",\n",
            "                \"similarity\": 72.33\n",
            "            }\n",
            "        }\n",
            "    }\n",
            "}\n",
            "Too many requests! Try again in a second.\n",
            "{\n",
            "    \"Prompt0\": {\n",
            "        \"UserPrompt\": \"Ø³Ù„Ø§Ù…ØŒ Ù…Ù† Ù…Ù‡Ø¯ÛŒ Ø§Ù…!\",\n",
            "        \"results\": {}\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test Case 2:**\n",
        "\n",
        "*   `top_k = 2`:   returns top 2 similar FAQ question\n",
        "\n",
        "\n",
        "*   `threshold = 25`: returns similar FAQ questions with similarity rate higher than 25%"
      ],
      "metadata": {
        "id": "HgqfQheYIZ7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "myPrompts = [\"Ú†Ø·ÙˆØ±ÛŒ Ø±Ù…Ø² Ù¾ÙˆÛŒØ§ Ø¨Ú¯ÛŒØ±Ù…ØŸ\", \"Ú†Ø·ÙˆØ±ÛŒ Ø´Ù…Ø§Ø±Ù‡ Ø´Ø¨Ø§ Ø¨Ú¯ÛŒØ±Ù…ØŸ\", \"Ø³Ù„Ø§Ù…ØŒ Ù…Ù† Ù…Ù‡Ø¯ÛŒ Ø§Ù…!\"]\n",
        "for prompt in myPrompts:\n",
        "    print(chatbot.call(prompt, top_k=2, threshold=25))\n",
        "    time.sleep(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "mCRCvFZ7Futm",
        "outputId": "41251359-d388-421c-bfe3-913ac1d474c2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[('UserPrompt:Ú†Ø·ÙˆØ±ÛŒ Ø±Ù…Ø² Ù¾ÙˆÛŒØ§ Ø¨Ú¯ÛŒØ±Ù…ØŸ', 'FAQ:Ø±Ù…Ø² Ù¾ÙˆÛŒØ§ Ø§Ø² Ú†Ù‡ Ø·Ø±ÛŒÙ‚ÛŒ ÙØ¹Ø§Ù„ Ù…ÛŒ Ø´ÙˆØ¯ØŸ', 'IndexOfFAQ = 8', 'Similarity = 72.33%'), ('UserPrompt:Ú†Ø·ÙˆØ±ÛŒ Ø±Ù…Ø² Ù¾ÙˆÛŒØ§ Ø¨Ú¯ÛŒØ±Ù…ØŸ', 'FAQ:Ø¨Ø±Ø§ÛŒ Ø§Ù†ØªÙ‚Ø§Ù„ ÙˆØ¬Ù‡ Ù¾Ø§ÛŒØ§ Ùˆ Ø³Ø§ØªÙ†Ø§ Ø¨Ø§ÛŒØ¯ Ø§Ø² Ú†Ù‡ Ø±Ù…Ø²ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯ØŸ', 'IndexOfFAQ = 3', 'Similarity = 39.92%')]]\n",
            "[[('UserPrompt:Ú†Ø·ÙˆØ±ÛŒ Ø´Ù…Ø§Ø±Ù‡ Ø´Ø¨Ø§ Ø¨Ú¯ÛŒØ±Ù…ØŸ', 'FAQ:Ø¨Ù‡ Ú†Ù‡ Ø·Ø±ÛŒÙ‚ÛŒ Ù…ÛŒ ØªÙˆØ§Ù† Ø´Ù…Ø§Ø±Ù‡ Ø´Ø¨Ø§ Ùˆ Ø­Ø³Ø§Ø¨ Ø±Ø§ Ø§Ø² Ø¨Ø§Ù†Ú© Ø±ÙØ§Ù‡ Ø¯Ø±ÛŒØ§ÙØª Ù†Ù…ÙˆØ¯ØŸ', 'IndexOfFAQ = 11', 'Similarity = 50.5%'), ('UserPrompt:Ú†Ø·ÙˆØ±ÛŒ Ø´Ù…Ø§Ø±Ù‡ Ø´Ø¨Ø§ Ø¨Ú¯ÛŒØ±Ù…ØŸ', 'FAQ:Ù…Ø¯Øª Ø²Ù…Ø§Ù† Ø¯Ø±ÛŒØ§ÙØª Ú©Ø§Ø±Øª ÙØ±Ø§Ø±ÙØ§Ù‡ Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ', 'IndexOfFAQ = 1', 'Similarity = 37.75%')]]\n",
            "[[]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test Case 3:**\n",
        "\n",
        "*   `top_k = 2`:   returns top 2 similar FAQ question\n",
        "\n",
        "\n",
        "*   `threshold = 50`: returns similar FAQ questions with similarity rate higher than 50%"
      ],
      "metadata": {
        "id": "rLWWrMY_IgC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "myPrompts = [\"Ú†Ø·ÙˆØ±ÛŒ Ø±Ù…Ø² Ù¾ÙˆÛŒØ§ Ø¨Ú¯ÛŒØ±Ù…ØŸ\", \"Ú†Ø·ÙˆØ±ÛŒ Ø´Ù…Ø§Ø±Ù‡ Ø´Ø¨Ø§ Ø¨Ú¯ÛŒØ±Ù…ØŸ\", \"Ø³Ù„Ø§Ù…ØŒ Ù…Ù† Ù…Ù‡Ø¯ÛŒ Ø§Ù…!\"]\n",
        "for prompt in myPrompts:\n",
        "    print(chatbot.call(prompt, top_k=2, threshold=50))\n",
        "    time.sleep(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SDHTglDhGsGc",
        "outputId": "609c0cf4-6711-4ea9-cb28-2f276c1a7b54"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[('UserPrompt:Ú†Ø·ÙˆØ±ÛŒ Ø±Ù…Ø² Ù¾ÙˆÛŒØ§ Ø¨Ú¯ÛŒØ±Ù…ØŸ', 'FAQ:Ø±Ù…Ø² Ù¾ÙˆÛŒØ§ Ø§Ø² Ú†Ù‡ Ø·Ø±ÛŒÙ‚ÛŒ ÙØ¹Ø§Ù„ Ù…ÛŒ Ø´ÙˆØ¯ØŸ', 'IndexOfFAQ = 8', 'Similarity = 72.33%')]]\n",
            "[[('UserPrompt:Ú†Ø·ÙˆØ±ÛŒ Ø´Ù…Ø§Ø±Ù‡ Ø´Ø¨Ø§ Ø¨Ú¯ÛŒØ±Ù…ØŸ', 'FAQ:Ø¨Ù‡ Ú†Ù‡ Ø·Ø±ÛŒÙ‚ÛŒ Ù…ÛŒ ØªÙˆØ§Ù† Ø´Ù…Ø§Ø±Ù‡ Ø´Ø¨Ø§ Ùˆ Ø­Ø³Ø§Ø¨ Ø±Ø§ Ø§Ø² Ø¨Ø§Ù†Ú© Ø±ÙØ§Ù‡ Ø¯Ø±ÛŒØ§ÙØª Ù†Ù…ÙˆØ¯ØŸ', 'IndexOfFAQ = 11', 'Similarity = 50.5%')]]\n",
            "[[]]\n"
          ]
        }
      ]
    }
  ]
}